{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6973834-b9fd-43c2-a97b-262ebc26cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efd1256-90d4-4607-8f80-11162d55e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843a8b19-2989-413f-a83e-bcc9e696ec32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e108c71b-952b-4a86-b9c8-12afdcce02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Path\n",
    "path = \"/root/autodl-tmp/Data/aclImdb/train/neg\"\n",
    "# Change the directory\n",
    "os.chdir(path)\n",
    "\n",
    "train_neg = []\n",
    "\n",
    "# Read text File\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        train_neg.append(f.read())\n",
    "  \n",
    "\n",
    "# iterate through all file\n",
    "for file in os.listdir():\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "  \n",
    "        # call read text file function\n",
    "        read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a6e832-c1ee-489b-ac70-11c187c4fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/autodl-tmp/Data/aclImdb/train/pos\"\n",
    "# Change the directory\n",
    "os.chdir(path)\n",
    "\n",
    "train_pos = []\n",
    "\n",
    "# Read text File\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        train_pos.append(f.read())\n",
    "  \n",
    "\n",
    "# iterate through all file\n",
    "for file in os.listdir():\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "  \n",
    "        # call read text file function\n",
    "        read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6385c854-5e07-443e-bb44-98a34521c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_pos)) # number of positive comments\n",
    "print(len(train_neg)) # number of negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f50e69-71e0-4c35-a922-1057465a25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = train_neg + train_pos\n",
    "y_train_neg = [0]*len(train_neg)\n",
    "y_train_pos = [1]*len(train_pos)\n",
    "y_train = np.array(y_train_neg + y_train_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5eb5c6-54b7-4019-8076-fdcb61b8401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = 10000\n",
    "tokenizer = Tokenizer(num_words=vocabulary)\n",
    "tokenizer.fit_on_texts(texts_train) # build dictionary\n",
    "\n",
    "word_index = tokenizer.word_index # word dictionary\n",
    "sequence_train = tokenizer.texts_to_sequences(texts_train) # text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58311747-8b99-4a0d-91ad-9d0458ac829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align sequences\n",
    "word_num = 500 # different with logistic regression\n",
    "X_train = preprocessing.sequence.pad_sequences(sequence_train, maxlen=word_num) # Pre-padding or removing values from the beginning of the sequence is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aae18bf-ffb5-4aee-a602-057f1d081ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d291df2e-917a-4246-a91a-b05712562b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 13:43:02.775556: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 13:43:03.512438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22312 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b4:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "state_dim = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary, embedding_dim, input_length=word_num))\n",
    "model.add(SimpleRNN(state_dim, return_sequences=False)) # only return last state\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17cf67-b3a6-4d55-a222-57e8cb72f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 13:43:05.934444: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 156s 246ms/step - loss: 0.5849 - acc: 0.6643 - val_loss: 0.4825 - val_acc: 0.7838\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 156s 250ms/step - loss: 0.3542 - acc: 0.8536 - val_loss: 0.5387 - val_acc: 0.7764\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 162s 259ms/step - loss: 0.2644 - acc: 0.8950 - val_loss: 0.3389 - val_acc: 0.8538\n"
     ]
    }
   ],
   "source": [
    "epochs = 3 # avoid overfitting\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435002c3-b98e-49f2-affe-a201b3e472c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
